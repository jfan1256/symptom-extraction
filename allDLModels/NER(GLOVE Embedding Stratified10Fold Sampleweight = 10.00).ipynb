{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.backend import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10395536577486349605\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9148379955\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4671794795857291019\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#from tensorflow.python.keras import backend as K\n",
    "#config = tf.compat.v1.ConfigProto(device_count = {'GPU': 1, 'CPU' : 49} )\n",
    "#sess = tf.compat.v1.Session(config=config) \n",
    "#K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp/ipykernel_9664/1604910362.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_group['Word'].tolist()  \n",
    "labels = data_group['Tag'].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34275 unique tokens.\n",
      "[[  115     0     0 ...     0     0     0]\n",
      " [   44   145   106 ...     0     0     0]\n",
      " [ 6315 15212   259 ...     0     0     0]\n",
      " ...\n",
      " [   42    70    33 ...     0     0     0]\n",
      " [   13   421  1398 ...     0     0     0]\n",
      " [  327   561  1373 ...     0     0     0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape of data tensor: (132094, 49)\n",
      "Shape of label tensor: (132094, 49)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "pad_tokens = pad_sequences(sequences, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "print(pad_tokens)\n",
    "pad_tags = pad_sequences(labels, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.3, train_size=0.7, random_state=2020)\n",
    "print(pad_tags)\n",
    "print('Shape of data tensor:', pad_tokens.shape)\n",
    "print('Shape of label tensor:', pad_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOVE Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(r'./GLOVE', 'glove.6B.300d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=49,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(embedding_layer)\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\envs\\ame=researchSymptomExtraction\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10..........\n",
      "1: started assigning sample weights\n",
      "1: finished assigning sample weights - 0.5018498085062245, 145.64912444113264\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 49, 64)           85248     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 49, 1)            33        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 345s 182ms/step - loss: 0.0199 - acc: 0.9966 - precision_m: 0.4319 - recall_m: 0.3101 - f1_m: 0.3378\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 345s 186ms/step - loss: 0.0065 - acc: 0.9982 - precision_m: 0.7602 - recall_m: 0.6901 - f1_m: 0.7049\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 346s 186ms/step - loss: 0.0053 - acc: 0.9984 - precision_m: 0.7976 - recall_m: 0.7400 - f1_m: 0.7498\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 344s 185ms/step - loss: 0.0047 - acc: 0.9986 - precision_m: 0.8200 - recall_m: 0.7642 - f1_m: 0.7759\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 343s 184ms/step - loss: 0.0042 - acc: 0.9987 - precision_m: 0.8390 - recall_m: 0.7870 - f1_m: 0.7987\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 343s 184ms/step - loss: 0.0038 - acc: 0.9988 - precision_m: 0.8446 - recall_m: 0.8031 - f1_m: 0.8107\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 344s 185ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.8584 - recall_m: 0.8207 - f1_m: 0.8278\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 343s 185ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8672 - recall_m: 0.8334 - f1_m: 0.8382\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 341s 184ms/step - loss: 0.0031 - acc: 0.9990 - precision_m: 0.8723 - recall_m: 0.8396 - f1_m: 0.8453\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 339s 183ms/step - loss: 0.0029 - acc: 0.9991 - precision_m: 0.8774 - recall_m: 0.8506 - f1_m: 0.8542\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 341s 184ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.8855 - recall_m: 0.8644 - f1_m: 0.8660\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 339s 183ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8877 - recall_m: 0.8628 - f1_m: 0.8657\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 339s 183ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8925 - recall_m: 0.8700 - f1_m: 0.8721\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 341s 183ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.8974 - recall_m: 0.8782 - f1_m: 0.8806\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 342s 184ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9007 - recall_m: 0.8810 - f1_m: 0.8822\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 340s 183ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9070 - recall_m: 0.8843 - f1_m: 0.8884\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 339s 182ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9109 - recall_m: 0.8939 - f1_m: 0.8955\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 339s 183ms/step - loss: 0.0021 - acc: 0.9994 - precision_m: 0.9114 - recall_m: 0.8948 - f1_m: 0.8962\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 338s 182ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9103 - recall_m: 0.8963 - f1_m: 0.8962\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 340s 183ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9173 - recall_m: 0.9007 - f1_m: 0.9022\n",
      "Score for fold 1: loss of 0.00838264636695385; acc of 0.9981868267059326; precision_m of 0.7102780938148499; recall_m of 0.6563717126846313; f1_m of 0.6535045504570007 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 2/10..........\n",
      "2: started assigning sample weights\n",
      "2: finished assigning sample weights - 0.5018496355692414, 145.66176059618073\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 336s 178ms/step - loss: 0.0137 - acc: 0.9971 - precision_m: 0.6623 - recall_m: 0.5286 - f1_m: 0.5598\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 329s 177ms/step - loss: 0.0044 - acc: 0.9987 - precision_m: 0.8245 - recall_m: 0.8018 - f1_m: 0.7999\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 331s 178ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.8561 - recall_m: 0.8379 - f1_m: 0.8351\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 328s 177ms/step - loss: 0.0031 - acc: 0.9991 - precision_m: 0.8693 - recall_m: 0.8524 - f1_m: 0.8509\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 331s 178ms/step - loss: 0.0028 - acc: 0.9992 - precision_m: 0.8845 - recall_m: 0.8674 - f1_m: 0.8667\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 332s 178ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8899 - recall_m: 0.8712 - f1_m: 0.8726\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 332s 179ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.9007 - recall_m: 0.8820 - f1_m: 0.8832\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 329s 177ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9059 - recall_m: 0.8901 - f1_m: 0.8900\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 339s 183ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9065 - recall_m: 0.8920 - f1_m: 0.8919\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 355s 191ms/step - loss: 0.0021 - acc: 0.9994 - precision_m: 0.9161 - recall_m: 0.9025 - f1_m: 0.9026\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 358s 192ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9139 - recall_m: 0.9025 - f1_m: 0.9012\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 403s 217ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9203 - recall_m: 0.9048 - f1_m: 0.9067\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 463s 249ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9237 - recall_m: 0.9055 - f1_m: 0.9084\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 456s 245ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9251 - recall_m: 0.9080 - f1_m: 0.9110\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 403s 217ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9261 - recall_m: 0.9165 - f1_m: 0.9158\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 384s 207ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9283 - recall_m: 0.9152 - f1_m: 0.9159\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 440s 237ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9264 - recall_m: 0.9161 - f1_m: 0.9156\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 425s 229ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9305 - recall_m: 0.9202 - f1_m: 0.9201\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 429s 231ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9314 - recall_m: 0.9221 - f1_m: 0.9211\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 428s 230ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9319 - recall_m: 0.9255 - f1_m: 0.9238\n",
      "Score for fold 2: loss of 0.005014336202293634; acc of 0.9988277554512024; precision_m of 0.7734789252281189; recall_m of 0.7273657917976379; f1_m of 0.7322619557380676 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 3/10..........\n",
      "3: started assigning sample weights\n",
      "3: finished assigning sample weights - 0.5018499814433267, 145.63649063984354\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 350s 185ms/step - loss: 0.0126 - acc: 0.9972 - precision_m: 0.6572 - recall_m: 0.5359 - f1_m: 0.5636\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 361s 194ms/step - loss: 0.0040 - acc: 0.9988 - precision_m: 0.8334 - recall_m: 0.8145 - f1_m: 0.8110\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 373s 201ms/step - loss: 0.0030 - acc: 0.9991 - precision_m: 0.8735 - recall_m: 0.8604 - f1_m: 0.8575\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 373s 201ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8961 - recall_m: 0.8784 - f1_m: 0.8780\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 375s 202ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9081 - recall_m: 0.8874 - f1_m: 0.8907\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 375s 202ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9071 - recall_m: 0.8937 - f1_m: 0.8932\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 378s 203ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9195 - recall_m: 0.9072 - f1_m: 0.9072\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 352s 190ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9170 - recall_m: 0.9053 - f1_m: 0.9050\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 363s 195ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9223 - recall_m: 0.9142 - f1_m: 0.9129\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 374s 201ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9250 - recall_m: 0.9145 - f1_m: 0.9145\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 365s 197ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9317 - recall_m: 0.9192 - f1_m: 0.9201\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 366s 197ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9317 - recall_m: 0.9217 - f1_m: 0.9215\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 369s 199ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9313 - recall_m: 0.9226 - f1_m: 0.9221\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 370s 199ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9338 - recall_m: 0.9228 - f1_m: 0.9229\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 367s 197ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9369 - recall_m: 0.9267 - f1_m: 0.9271\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 354s 190ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9345 - recall_m: 0.9247 - f1_m: 0.9248\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 368s 198ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9399 - recall_m: 0.9296 - f1_m: 0.9303\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 368s 198ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9362 - recall_m: 0.9319 - f1_m: 0.9294\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 371s 200ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9382 - recall_m: 0.9298 - f1_m: 0.9297\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 370s 199ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9380 - recall_m: 0.9348 - f1_m: 0.9323\n",
      "Score for fold 3: loss of 0.0034683311823755503; acc of 0.9990918040275574; precision_m of 0.784105658531189; recall_m of 0.7578145861625671; f1_m of 0.7548285722732544 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 4/10..........\n",
      "4: started assigning sample weights\n",
      "4: finished assigning sample weights - 0.5018498085062245, 145.64912444113264\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 444s 235ms/step - loss: 0.0110 - acc: 0.9975 - precision_m: 0.6719 - recall_m: 0.5628 - f1_m: 0.5872\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 410s 221ms/step - loss: 0.0036 - acc: 0.9989 - precision_m: 0.8498 - recall_m: 0.8449 - f1_m: 0.8367\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 408s 220ms/step - loss: 0.0027 - acc: 0.9992 - precision_m: 0.8860 - recall_m: 0.8797 - f1_m: 0.8742\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 405s 218ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.8983 - recall_m: 0.8883 - f1_m: 0.8857\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 404s 217ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9117 - recall_m: 0.9020 - f1_m: 0.9001\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 404s 218ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9134 - recall_m: 0.9059 - f1_m: 0.9035\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 405s 218ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9201 - recall_m: 0.9111 - f1_m: 0.9096\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 409s 220ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9226 - recall_m: 0.9153 - f1_m: 0.9134\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 416s 224ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9263 - recall_m: 0.9203 - f1_m: 0.9184\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 411s 221ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9275 - recall_m: 0.9209 - f1_m: 0.9191\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 409s 220ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9352 - recall_m: 0.9245 - f1_m: 0.9256\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 408s 220ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9339 - recall_m: 0.9206 - f1_m: 0.9220\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 408s 220ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9356 - recall_m: 0.9256 - f1_m: 0.9259\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 407s 219ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9391 - recall_m: 0.9244 - f1_m: 0.9266\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 400s 215ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9389 - recall_m: 0.9286 - f1_m: 0.9287\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 402s 216ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9381 - recall_m: 0.9281 - f1_m: 0.9285\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 410s 221ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9330 - recall_m: 0.9231 - f1_m: 0.9225\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 409s 220ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9386 - recall_m: 0.9323 - f1_m: 0.9307\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 409s 220ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9330 - f1_m: 0.9320\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 408s 220ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9432 - recall_m: 0.9365 - f1_m: 0.9351\n",
      "Score for fold 4: loss of 0.003217004705220461; acc of 0.9992229342460632; precision_m of 0.833143413066864; recall_m of 0.7933250069618225; f1_m of 0.7981456518173218 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 5/10..........\n",
      "5: started assigning sample weights\n",
      "5: finished assigning sample weights - 0.5018508305046226, 145.57449730031652\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 439s 233ms/step - loss: 0.0110 - acc: 0.9978 - precision_m: 0.6962 - recall_m: 0.5887 - f1_m: 0.6116\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 433s 233ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8649 - recall_m: 0.8560 - f1_m: 0.8507\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 464s 249ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8886 - recall_m: 0.8781 - f1_m: 0.8756\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9074 - recall_m: 0.8967 - f1_m: 0.8950\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9192 - recall_m: 0.9091 - f1_m: 0.9081\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 463s 249ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9209 - recall_m: 0.9127 - f1_m: 0.9110\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 463s 249ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9289 - recall_m: 0.9198 - f1_m: 0.9183\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9306 - recall_m: 0.9235 - f1_m: 0.9216\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9300 - recall_m: 0.9254 - f1_m: 0.9232\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9317 - recall_m: 0.9268 - f1_m: 0.9241\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9344 - recall_m: 0.9303 - f1_m: 0.9273\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9370 - recall_m: 0.9293 - f1_m: 0.9288\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9380 - recall_m: 0.9302 - f1_m: 0.9298\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9411 - recall_m: 0.9338 - f1_m: 0.9329\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9417 - recall_m: 0.9334 - f1_m: 0.9335\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9416 - recall_m: 0.9343 - f1_m: 0.9336\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9455 - recall_m: 0.9373 - f1_m: 0.9376\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9424 - recall_m: 0.9324 - f1_m: 0.9328\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 465s 250ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9380 - recall_m: 0.9310 - f1_m: 0.9303\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 464s 250ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9459 - recall_m: 0.9387 - f1_m: 0.9380\n",
      "Score for fold 5: loss of 0.0028099745977669954; acc of 0.9993078708648682; precision_m of 0.8411281704902649; recall_m of 0.8073114156723022; f1_m of 0.8121386170387268 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 6/10..........\n",
      "6: started assigning sample weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: finished assigning sample weights - 0.5018508305046226, 145.57449730031652\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 477s 253ms/step - loss: 0.0109 - acc: 0.9978 - precision_m: 0.6994 - recall_m: 0.5932 - f1_m: 0.6154\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0032 - acc: 0.9991 - precision_m: 0.8670 - recall_m: 0.8617 - f1_m: 0.8549\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 471s 254ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9019 - recall_m: 0.8892 - f1_m: 0.8879\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 471s 253ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9170 - recall_m: 0.9012 - f1_m: 0.9019\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9276 - recall_m: 0.9143 - f1_m: 0.9152\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 469s 253ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9326 - recall_m: 0.9179 - f1_m: 0.9200\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9315 - recall_m: 0.9218 - f1_m: 0.9215\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9333 - recall_m: 0.9235 - f1_m: 0.9233\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9377 - recall_m: 0.9281 - f1_m: 0.9283\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9407 - recall_m: 0.9287 - f1_m: 0.9299\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9374 - recall_m: 0.9306 - f1_m: 0.9290\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 471s 253ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9411 - recall_m: 0.9318 - f1_m: 0.9321\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9414 - recall_m: 0.9351 - f1_m: 0.9341\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9390 - recall_m: 0.9307 - f1_m: 0.9308\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 469s 253ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9425 - recall_m: 0.9321 - f1_m: 0.9329\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9415 - recall_m: 0.9316 - f1_m: 0.9322\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 469s 253ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9458 - recall_m: 0.9386 - f1_m: 0.9380\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9483 - recall_m: 0.9412 - f1_m: 0.9409\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 469s 253ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9478 - recall_m: 0.9393 - f1_m: 0.9400\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 470s 253ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9503 - recall_m: 0.9407 - f1_m: 0.9413\n",
      "Score for fold 6: loss of 0.002574215643107891; acc of 0.9993371367454529; precision_m of 0.8413464426994324; recall_m of 0.8127831816673279; f1_m of 0.81545490026474 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 7/10..........\n",
      "7: started assigning sample weights\n",
      "7: finished assigning sample weights - 0.5018507440364914, 145.58080808080808\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 547s 291ms/step - loss: 0.0116 - acc: 0.9975 - precision_m: 0.6862 - recall_m: 0.5720 - f1_m: 0.5974\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0035 - acc: 0.9990 - precision_m: 0.8544 - recall_m: 0.8492 - f1_m: 0.8411\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8904 - recall_m: 0.8842 - f1_m: 0.8793\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9045 - recall_m: 0.8994 - f1_m: 0.8959\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9150 - recall_m: 0.9068 - f1_m: 0.9044\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9221 - recall_m: 0.9150 - f1_m: 0.9132\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9292 - recall_m: 0.9253 - f1_m: 0.9219\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9303 - recall_m: 0.9270 - f1_m: 0.9237\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9344 - recall_m: 0.9269 - f1_m: 0.9256\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9315 - recall_m: 0.9280 - f1_m: 0.9251\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9399 - recall_m: 0.9301 - f1_m: 0.9304\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9443 - recall_m: 0.9337 - f1_m: 0.9345\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9451 - recall_m: 0.9371 - f1_m: 0.9368\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9341 - f1_m: 0.9330\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9455 - recall_m: 0.9336 - f1_m: 0.9354\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9426 - recall_m: 0.9335 - f1_m: 0.9341\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9475 - recall_m: 0.9414 - f1_m: 0.9406\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9457 - recall_m: 0.9401 - f1_m: 0.9391\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9459 - recall_m: 0.9403 - f1_m: 0.9390\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9513 - recall_m: 0.9423 - f1_m: 0.9428\n",
      "Score for fold 7: loss of 0.0021900811698287725; acc of 0.9994118809700012; precision_m of 0.8319073915481567; recall_m of 0.8100249171257019; f1_m of 0.811424195766449 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 8/10..........\n",
      "8: started assigning sample weights\n",
      "8: finished assigning sample weights - 0.50185065756839, 145.5871194488409\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 524s 279ms/step - loss: 0.0125 - acc: 0.9973 - precision_m: 0.6967 - recall_m: 0.5365 - f1_m: 0.5745\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 520s 280ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8589 - recall_m: 0.8539 - f1_m: 0.8463\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 514s 277ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.8980 - recall_m: 0.8896 - f1_m: 0.8868\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 503s 270ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9194 - recall_m: 0.9080 - f1_m: 0.9077\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9212 - recall_m: 0.9142 - f1_m: 0.9124\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9274 - recall_m: 0.9175 - f1_m: 0.9172\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9330 - recall_m: 0.9236 - f1_m: 0.9235\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9339 - recall_m: 0.9304 - f1_m: 0.9270\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 504s 272ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9390 - recall_m: 0.9295 - f1_m: 0.9294\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9376 - recall_m: 0.9331 - f1_m: 0.9306\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9388 - recall_m: 0.9320 - f1_m: 0.9311\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9445 - recall_m: 0.9372 - f1_m: 0.9370\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9438 - recall_m: 0.9388 - f1_m: 0.9371\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9424 - recall_m: 0.9381 - f1_m: 0.9364\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9436 - recall_m: 0.9401 - f1_m: 0.9378\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9473 - recall_m: 0.9413 - f1_m: 0.9408\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 506s 272ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9474 - recall_m: 0.9412 - f1_m: 0.9405\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9484 - recall_m: 0.9441 - f1_m: 0.9427\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9512 - recall_m: 0.9432 - f1_m: 0.9438\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 509s 274ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9478 - recall_m: 0.9402 - f1_m: 0.9401\n",
      "Score for fold 8: loss of 0.001745042041875422; acc of 0.9994285106658936; precision_m of 0.8358820080757141; recall_m of 0.8427194952964783; f1_m of 0.8281828761100769 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 9/10..........\n",
      "9: started assigning sample weights\n",
      "9: finished assigning sample weights - 0.50185065756839, 145.5871194488409\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 570s 303ms/step - loss: 0.0124 - acc: 0.9974 - precision_m: 0.6674 - recall_m: 0.5428 - f1_m: 0.5725\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8620 - recall_m: 0.8527 - f1_m: 0.8472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.9004 - recall_m: 0.8912 - f1_m: 0.8889\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9169 - recall_m: 0.9033 - f1_m: 0.9042\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9234 - recall_m: 0.9164 - f1_m: 0.9145\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9340 - recall_m: 0.9205 - f1_m: 0.9222\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9348 - recall_m: 0.9259 - f1_m: 0.9253\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9370 - recall_m: 0.9248 - f1_m: 0.9257\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 562s 302ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9392 - recall_m: 0.9310 - f1_m: 0.9298\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9392 - recall_m: 0.9292 - f1_m: 0.9300\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9409 - recall_m: 0.9339 - f1_m: 0.9330\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 562s 302ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9434 - recall_m: 0.9346 - f1_m: 0.9353\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9444 - recall_m: 0.9356 - f1_m: 0.9359\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9471 - recall_m: 0.9388 - f1_m: 0.9392\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9449 - recall_m: 0.9387 - f1_m: 0.9382\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9491 - recall_m: 0.9429 - f1_m: 0.9423\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9486 - recall_m: 0.9420 - f1_m: 0.9414\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9500 - recall_m: 0.9441 - f1_m: 0.9433\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 561s 302ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9482 - recall_m: 0.9405 - f1_m: 0.9404\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 562s 302ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9511 - recall_m: 0.9438 - f1_m: 0.9436\n",
      "Score for fold 9: loss of 0.0016703057335689664; acc of 0.9995524883270264; precision_m of 0.8785880208015442; recall_m of 0.8651152849197388; f1_m of 0.8638412356376648 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Training on fold 10/10..........\n",
      "10: started assigning sample weights\n",
      "10: finished assigning sample weights - 0.50185065756839, 145.5871194488409\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 510s 271ms/step - loss: 0.0121 - acc: 0.9974 - precision_m: 0.6859 - recall_m: 0.5676 - f1_m: 0.5935\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8627 - recall_m: 0.8531 - f1_m: 0.8481\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 506s 272ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.8939 - recall_m: 0.8886 - f1_m: 0.8839\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9139 - recall_m: 0.9075 - f1_m: 0.9041\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9224 - recall_m: 0.9183 - f1_m: 0.9153\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9324 - recall_m: 0.9239 - f1_m: 0.9233\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9355 - recall_m: 0.9294 - f1_m: 0.9278\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9372 - recall_m: 0.9290 - f1_m: 0.9276\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9368 - recall_m: 0.9329 - f1_m: 0.9301\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 508s 274ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9392 - recall_m: 0.9333 - f1_m: 0.9318\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9467 - recall_m: 0.9392 - f1_m: 0.9390\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9399 - recall_m: 0.9342 - f1_m: 0.9329\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9430 - recall_m: 0.9382 - f1_m: 0.9369\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9452 - recall_m: 0.9408 - f1_m: 0.9394\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9485 - recall_m: 0.9429 - f1_m: 0.9423\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9490 - recall_m: 0.9460 - f1_m: 0.9440\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9491 - recall_m: 0.9410 - f1_m: 0.9416\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9458 - recall_m: 0.9415 - f1_m: 0.9397\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 503s 271ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9498 - recall_m: 0.9455 - f1_m: 0.9441\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 504s 271ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9480 - recall_m: 0.9428 - f1_m: 0.9420\n",
      "Score for fold 10: loss of 0.0016075328458100557; acc of 0.9995244741439819; precision_m of 0.8585010170936584; recall_m of 0.8396969437599182; f1_m of 0.8415869474411011 %\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 999)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/10..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_test = pad_tokens[train_index], pad_tokens[test_index]\n",
    "    y_train, y_test = pad_tags[train_index], pad_tags[test_index]\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started assigning sample weights\")\n",
    "    weights = class_weight.compute_class_weight(\n",
    "                                                class_weight ='balanced', \n",
    "                                                classes = np.unique(np.ravel(y_train,order='C')), \n",
    "                                                y = np.ravel(y_train,order='C')\n",
    "                                                )\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1]+10.00)\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "    \n",
    "    print(str(fold_number) + \": finished assigning sample weights - \" + str(weights[0]) + ', ' + str(weights[1] + 10.00))\n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = None \n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=64, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_test, y_test, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.00838264636695385 - Accuracy: 0.9981868267059326 - Precision: 0.7102780938148499 - Recall: 0.6563717126846313 - F1: 0.6535045504570007%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.005014336202293634 - Accuracy: 0.9988277554512024 - Precision: 0.7734789252281189 - Recall: 0.7273657917976379 - F1: 0.7322619557380676%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.0034683311823755503 - Accuracy: 0.9990918040275574 - Precision: 0.784105658531189 - Recall: 0.7578145861625671 - F1: 0.7548285722732544%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.003217004705220461 - Accuracy: 0.9992229342460632 - Precision: 0.833143413066864 - Recall: 0.7933250069618225 - F1: 0.7981456518173218%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.0028099745977669954 - Accuracy: 0.9993078708648682 - Precision: 0.8411281704902649 - Recall: 0.8073114156723022 - F1: 0.8121386170387268%\n",
      "-----------\n",
      "> Fold 6 - Loss: 0.002574215643107891 - Accuracy: 0.9993371367454529 - Precision: 0.8413464426994324 - Recall: 0.8127831816673279 - F1: 0.81545490026474%\n",
      "-----------\n",
      "> Fold 7 - Loss: 0.0021900811698287725 - Accuracy: 0.9994118809700012 - Precision: 0.8319073915481567 - Recall: 0.8100249171257019 - F1: 0.811424195766449%\n",
      "-----------\n",
      "> Fold 8 - Loss: 0.001745042041875422 - Accuracy: 0.9994285106658936 - Precision: 0.8358820080757141 - Recall: 0.8427194952964783 - F1: 0.8281828761100769%\n",
      "-----------\n",
      "> Fold 9 - Loss: 0.0016703057335689664 - Accuracy: 0.9995524883270264 - Precision: 0.8785880208015442 - Recall: 0.8651152849197388 - F1: 0.8638412356376648%\n",
      "-----------\n",
      "> Fold 10 - Loss: 0.0016075328458100557 - Accuracy: 0.9995244741439819 - Precision: 0.8585010170936584 - Recall: 0.8396969437599182 - F1: 0.8415869474411011%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.999189168214798 (+- 0.00039156480580215526)\n",
      "> Precision: 0.8188359141349792 (+- 0.046756484094958015)\n",
      "> Recall: 0.7912528336048126 (+- 0.05909485344771352)\n",
      "> F1: 0.7911369502544403 (+- 0.05867187030011423)\n",
      "> Loss: 0.0032679470488801597\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tags = model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositive = 0 \n",
    "falsePositive = 0\n",
    "trueNegative = 0 \n",
    "falseNegative = 0\n",
    "index = 0\n",
    "for tag, predTag in zip(test_tags, predict_tags):\n",
    "    for symptomTag, symptomPred in zip (tag, predTag):\n",
    "        if symptomPred >= 0.50 and symptomTag == 1:\n",
    "            truePositive = truePositive + 1\n",
    "        elif symptomPred >= 0.50 and symptomTag == 0:\n",
    "            falsePositive = falsePositive + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 0:\n",
    "            trueNegative = trueNegative + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 1:\n",
    "            falseNegative = falseNegative + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True postitive: ' + str(truePositive))\n",
    "print('False postitive: ' + str(falsePositive))\n",
    "print('True negative: ' + str(trueNegative))\n",
    "print('False negative: ' + str(falseNegative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (truePositive)/(truePositive+falsePositive)\n",
    "recall = (truePositive)/(truePositive+falseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str((truePositive+trueNegative)/(truePositive+trueNegative+falsePositive+falseNegative)))\n",
    "print('Precision: ' + str((truePositive)/(truePositive+falsePositive)))\n",
    "print('Recall: ' + str((truePositive)/(truePositive+falseNegative)))\n",
    "print('F1: ' + str((2*precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(pad_tokens, pad_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
